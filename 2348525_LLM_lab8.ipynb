{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "xePcVTXt_6lr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBzMV48n_wBA",
        "outputId": "d0069c88-12d5-440a-8a2d-adf207c1bf52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single text prediction: 1\n",
            "Batch predictions: [1, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Function to classify a single text\n",
        "def classify_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = outputs.logits.argmax(dim=-1)\n",
        "    return predictions.item()\n",
        "\n",
        "# Function to classify a batch of texts\n",
        "def classify_texts(texts):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = outputs.logits.argmax(dim=-1)\n",
        "    return predictions.tolist()\n",
        "\n",
        "# Example usage\n",
        "single_text = \"I love this product!\"\n",
        "batch_texts = [\"I love this product!\", \"This is terrible.\", \"It's okay, nothing special.\"]\n",
        "\n",
        "# Classify a single text\n",
        "predicted_class = classify_text(single_text)\n",
        "print(f\"Single text prediction: {predicted_class}\")\n",
        "\n",
        "# Classify a batch of texts\n",
        "predicted_classes = classify_texts(batch_texts)\n",
        "print(f\"Batch predictions: {predicted_classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "656dQpry_-R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Load the processor and model for CLIP\n",
        "model_name = \"openai/clip-vit-base-patch32\"\n",
        "processor = CLIPProcessor.from_pretrained(model_name)\n",
        "model = CLIPModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to calculate similarity between a single text and image\n",
        "def calculate_similarity(text, image_path):\n",
        "    image = Image.open(image_path)\n",
        "    inputs = processor(text=text, images=image, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    similarity = torch.nn.functional.cosine_similarity(outputs.text_embeds, outputs.image_embeds)\n",
        "    return similarity.item()\n",
        "\n",
        "# Function to calculate similarities for multiple text-image pairs\n",
        "def batch_similarity(text_image_pairs):\n",
        "    similarities = []\n",
        "    for text, image_path in text_image_pairs:\n",
        "        similarity = calculate_similarity(text, image_path)\n",
        "        similarities.append(similarity)\n",
        "    return similarities\n",
        "\n",
        "# Example usage\n",
        "single_text = \"A photo of a cat.\"\n",
        "single_image_path = \"/content/jamie-street-0nk6XZp7_1E-unsplash.jpg\"  ,
        "batch_text_image_pairs = [\n",
        "    (\"A photo of a cat.\", \"/content/igor-kasalovic-tNDvFkxkBHo-unsplash.jpg\"),\n",
        "    (\"A photo of a dog.\", \"/content/jamie-street-0nk6XZp7_1E-unsplash.jpg\"),\n",
        "    (\"A photo of a sunset.\", \"/content/max-sandelin-FRpJVO1AjlA-unsplash.jpg\")\n",
        "]\n",
        "\n",
        "# Calculate similarity for a single text-image pair\n",
        "similarity = calculate_similarity(single_text, single_image_path)\n",
        "print(f\"Similarity for single pair: {similarity}\")\n",
        "\n",
        "# Calculate similarities for a batch of text-image pairs\n",
        "batch_similarities = batch_similarity(batch_text_image_pairs)\n",
        "print(f\"Batch similarities: {batch_similarities}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W2DHH5e_5y0",
        "outputId": "a01dd884-147f-453d-88cf-0ba9eb2a4d19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity for single pair: 0.20058850944042206\n",
            "Batch similarities: [0.1872957944869995, 0.2763947546482086, 0.18386612832546234]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mb7Hc10jAB-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
